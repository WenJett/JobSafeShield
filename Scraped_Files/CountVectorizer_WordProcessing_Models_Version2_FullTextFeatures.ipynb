{"cells":[{"cell_type":"markdown","metadata":{"id":"HkSKd91EbLbv"},"source":["# BT4012 Without Text Analysis"]},{"cell_type":"markdown","metadata":{"id":"7YMtzwY_bxSt"},"source":["### Setting up the environment"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":1387,"status":"ok","timestamp":1700653988876,"user":{"displayName":"lo zh","userId":"05866467891459786403"},"user_tz":-480},"id":"-rpBt19SbwIw"},"outputs":[],"source":["# libraries importing\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import sklearn"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":573},"executionInfo":{"elapsed":23674,"status":"ok","timestamp":1700654013062,"user":{"displayName":"lo zh","userId":"05866467891459786403"},"user_tz":-480},"id":"YRHiTV1Zb4vl","outputId":"8c7c934b-48ae-4470-cf08-cfb81e595fa8"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>job_id</th>\n","      <th>title</th>\n","      <th>location</th>\n","      <th>department</th>\n","      <th>salary_range</th>\n","      <th>company_profile</th>\n","      <th>description</th>\n","      <th>requirements</th>\n","      <th>benefits</th>\n","      <th>telecommuting</th>\n","      <th>has_company_logo</th>\n","      <th>has_questions</th>\n","      <th>employment_type</th>\n","      <th>required_experience</th>\n","      <th>required_education</th>\n","      <th>industry</th>\n","      <th>function</th>\n","      <th>fraudulent</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Marketing Intern</td>\n","      <td>US, NY, New York</td>\n","      <td>Marketing</td>\n","      <td>NaN</td>\n","      <td>We're Food52, and we've created a groundbreaki...</td>\n","      <td>Food52, a fast-growing, James Beard Award-winn...</td>\n","      <td>Experience with content management systems a m...</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>Other</td>\n","      <td>Internship</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Marketing</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Customer Service - Cloud Video Production</td>\n","      <td>NZ, , Auckland</td>\n","      <td>Success</td>\n","      <td>NaN</td>\n","      <td>90 Seconds, the worlds Cloud Video Production ...</td>\n","      <td>Organised - Focused - Vibrant - Awesome!Do you...</td>\n","      <td>What we expect from you:Your key responsibilit...</td>\n","      <td>What you will get from usThrough being part of...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>Full-time</td>\n","      <td>Not Applicable</td>\n","      <td>NaN</td>\n","      <td>Marketing and Advertising</td>\n","      <td>Customer Service</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Commissioning Machinery Assistant (CMA)</td>\n","      <td>US, IA, Wever</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Valor Services provides Workforce Solutions th...</td>\n","      <td>Our client, located in Houston, is actively se...</td>\n","      <td>Implement pre-commissioning and commissioning ...</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Account Executive - Washington DC</td>\n","      <td>US, DC, Washington</td>\n","      <td>Sales</td>\n","      <td>NaN</td>\n","      <td>Our passion for improving quality of life thro...</td>\n","      <td>THE COMPANY: ESRI – Environmental Systems Rese...</td>\n","      <td>EDUCATION: Bachelor’s or Master’s in GIS, busi...</td>\n","      <td>Our culture is anything but corporate—we have ...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>Full-time</td>\n","      <td>Mid-Senior level</td>\n","      <td>Bachelor's Degree</td>\n","      <td>Computer Software</td>\n","      <td>Sales</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Bill Review Manager</td>\n","      <td>US, FL, Fort Worth</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>SpotSource Solutions LLC is a Global Human Cap...</td>\n","      <td>JOB TITLE: Itemization Review ManagerLOCATION:...</td>\n","      <td>QUALIFICATIONS:RN license in the State of Texa...</td>\n","      <td>Full Benefits Offered</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Full-time</td>\n","      <td>Mid-Senior level</td>\n","      <td>Bachelor's Degree</td>\n","      <td>Hospital &amp; Health Care</td>\n","      <td>Health Care Provider</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   job_id                                      title            location  \\\n","0       1                           Marketing Intern    US, NY, New York   \n","1       2  Customer Service - Cloud Video Production      NZ, , Auckland   \n","2       3    Commissioning Machinery Assistant (CMA)       US, IA, Wever   \n","3       4          Account Executive - Washington DC  US, DC, Washington   \n","4       5                        Bill Review Manager  US, FL, Fort Worth   \n","\n","  department salary_range                                    company_profile  \\\n","0  Marketing          NaN  We're Food52, and we've created a groundbreaki...   \n","1    Success          NaN  90 Seconds, the worlds Cloud Video Production ...   \n","2        NaN          NaN  Valor Services provides Workforce Solutions th...   \n","3      Sales          NaN  Our passion for improving quality of life thro...   \n","4        NaN          NaN  SpotSource Solutions LLC is a Global Human Cap...   \n","\n","                                         description  \\\n","0  Food52, a fast-growing, James Beard Award-winn...   \n","1  Organised - Focused - Vibrant - Awesome!Do you...   \n","2  Our client, located in Houston, is actively se...   \n","3  THE COMPANY: ESRI – Environmental Systems Rese...   \n","4  JOB TITLE: Itemization Review ManagerLOCATION:...   \n","\n","                                        requirements  \\\n","0  Experience with content management systems a m...   \n","1  What we expect from you:Your key responsibilit...   \n","2  Implement pre-commissioning and commissioning ...   \n","3  EDUCATION: Bachelor’s or Master’s in GIS, busi...   \n","4  QUALIFICATIONS:RN license in the State of Texa...   \n","\n","                                            benefits  telecommuting  \\\n","0                                                NaN              0   \n","1  What you will get from usThrough being part of...              0   \n","2                                                NaN              0   \n","3  Our culture is anything but corporate—we have ...              0   \n","4                              Full Benefits Offered              0   \n","\n","   has_company_logo  has_questions employment_type required_experience  \\\n","0                 1              0           Other          Internship   \n","1                 1              0       Full-time      Not Applicable   \n","2                 1              0             NaN                 NaN   \n","3                 1              0       Full-time    Mid-Senior level   \n","4                 1              1       Full-time    Mid-Senior level   \n","\n","  required_education                   industry              function  \\\n","0                NaN                        NaN             Marketing   \n","1                NaN  Marketing and Advertising      Customer Service   \n","2                NaN                        NaN                   NaN   \n","3  Bachelor's Degree          Computer Software                 Sales   \n","4  Bachelor's Degree     Hospital & Health Care  Health Care Provider   \n","\n","   fraudulent  \n","0           0  \n","1           0  \n","2           0  \n","3           0  \n","4           0  "]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# setting up\n","# import packages here\n","# from google.colab import drive\n","# drive.mount('/content/drive')\n","# url = '/content/drive/MyDrive/fake_job_postings.csv'\n","\n","# import from github repo\n","url = 'https://raw.githubusercontent.com/LordZhiHao/BT4012_Fraud_Analytics_Project/main/fake_job_postings.csv'\n","\n","# read data\n","data = pd.read_csv(url)\n","df = data.copy()\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"S_POrZFKc0qK"},"source":["### Handling Null Values\n","\n","EDA plz do refer other scripts\n","\n","Will dive straight into handling the null values and outliers"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1700654013062,"user":{"displayName":"lo zh","userId":"05866467891459786403"},"user_tz":-480},"id":"Dq3mU1ySdLqz"},"outputs":[],"source":["# keep track of what columns to keep and drop\n","cols_to_keep = []\n","cols_to_drop = []"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1700654013063,"user":{"displayName":"lo zh","userId":"05866467891459786403"},"user_tz":-480},"id":"qp3NvNXTcy9i","outputId":"5efea475-7102-4e71-9b0e-c5ed90e17c5a"},"outputs":[{"data":{"text/plain":["job_id                 False\n","title                  False\n","location                True\n","department              True\n","salary_range            True\n","company_profile         True\n","description             True\n","requirements            True\n","benefits                True\n","telecommuting          False\n","has_company_logo       False\n","has_questions          False\n","employment_type         True\n","required_experience     True\n","required_education      True\n","industry                True\n","function                True\n","fraudulent             False\n","dtype: bool"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# check for NA values\n","df.isna().any()"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1700654013063,"user":{"displayName":"lo zh","userId":"05866467891459786403"},"user_tz":-480},"id":"qSbNfu3Lcz4P","outputId":"e3d5c6da-bcf4-445e-ff5e-f6da2d4c5fac"},"outputs":[{"data":{"text/plain":["job_id                     0\n","title                      0\n","location                 346\n","department             11547\n","salary_range           15012\n","company_profile         3308\n","description                1\n","requirements            2696\n","benefits                7212\n","telecommuting              0\n","has_company_logo           0\n","has_questions              0\n","employment_type         3471\n","required_experience     7050\n","required_education      8105\n","industry                4903\n","function                6455\n","fraudulent                 0\n","dtype: int64"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# check for num of na values\n","df.isna().sum()"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":3387,"status":"ok","timestamp":1700654016444,"user":{"displayName":"lo zh","userId":"05866467891459786403"},"user_tz":-480},"id":"_Pgm3AEbcz6d"},"outputs":[],"source":["# handle location and description first since easier\n","\n","# handle location - split into nation and city and fillna with unknown\n","df['location'] = df['location'].fillna('NA, Unknown')\n","df['country'] = df['location'].apply(lambda x : x.strip()[:2])\n","df['city'] = df['location'].apply(lambda x : x.split(',')[-1])\n","\n","# a lot of sparse values noted for countries, may lead to unexpected results - to handle - keep countries with counts >10 only and put unknown for the rest\n","ls_of_countries = [country if df[df['country']==country]['country'].count() >= 10 else 'NA' for country in df['country'].unique()]\n","df['country'] = df['country'].apply(lambda x : x if x in ls_of_countries else 'NA')\n","\n","ls_of_cities = [city if df[df['city']==city]['city'].count() >= 10 else 'Unknown' for city in df['city'].unique()]\n","df['city'] = df['city'].apply(lambda x : x if x in ls_of_cities else 'Unknown')\n","\n","# keep track in cols_to_keep and cols_to_drop\n","cols_to_keep.append('country')\n","cols_to_keep.append('city')\n","cols_to_drop.append('location')"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1700654017758,"user":{"displayName":"lo zh","userId":"05866467891459786403"},"user_tz":-480},"id":"pIwES-_9c0Hk"},"outputs":[],"source":["# handle description - convert to binary - with or without\n","df['has_description'] = df['description'].apply(lambda x: 0 if pd.isna(x) else 1)\n","\n","# keep track in cols_to_keep and cols_to_drop\n","cols_to_keep.append('has_description')\n","cols_to_drop.append('description')"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":1473,"status":"ok","timestamp":1700654019226,"user":{"displayName":"lo zh","userId":"05866467891459786403"},"user_tz":-480},"id":"hhlSmgcNc0MZ"},"outputs":[],"source":["# handle department - q a lot of departments - keep only those with high count and take everything else as unknown\n","ls_of_dept = [dept if df[df['department']==dept]['department'].count() >= 10 else 'Unknown' for dept in df['department'].unique()]\n","df['has_department'] = df['department'].apply(lambda x : x if x in ls_of_dept else 'Unknown')\n","\n","# keep track in cols_to_keep and cols_to_drop\n","cols_to_keep.append('has_department')"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":38,"status":"ok","timestamp":1700654019227,"user":{"displayName":"lo zh","userId":"05866467891459786403"},"user_tz":-480},"id":"1su4ivP_c0PM"},"outputs":[],"source":["# handle salary_range - q a lot of ranges - keep as binary - has_salary or not\n","df['has_salary'] = df['salary_range'].apply(lambda x : 0 if pd.isna(x) else 1)\n","\n","# keep track in cols_to_keep and cols_to_drop\n","cols_to_keep.append('has_salary')\n","cols_to_drop.append('salary_range')"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36,"status":"ok","timestamp":1700654019227,"user":{"displayName":"lo zh","userId":"05866467891459786403"},"user_tz":-480},"id":"eewGxQ_ncgZ-","outputId":"22510eef-673c-41c8-f776-d308aa388826"},"outputs":[{"data":{"text/plain":["['location', 'description', 'salary_range']"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["cols_to_drop # handled these colummns"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":35,"status":"ok","timestamp":1700654019228,"user":{"displayName":"lo zh","userId":"05866467891459786403"},"user_tz":-480},"id":"dTrkpQ2eliPh"},"outputs":[],"source":["# handle company_profile, requirements and benefits next - for simplicity - keep as binary - has or not\n","df['has_company_profile'] = df['company_profile'].apply(lambda x : 0 if pd.isna(x) else 1)\n","df['has_requirements'] = df['requirements'].apply(lambda x : 0 if pd.isna(x) else 1)\n","df['has_benefits'] = df['benefits'].apply(lambda x : 0 if pd.isna(x) else 1)\n","\n","# keep track in cols_to_keep and cols_to_drop\n","cols_to_keep.append('has_company_profile')\n","cols_to_keep.append('has_requirements')\n","cols_to_keep.append('has_benefits')"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":35,"status":"ok","timestamp":1700654019228,"user":{"displayName":"lo zh","userId":"05866467891459786403"},"user_tz":-480},"id":"HsOppqlPmdW8"},"outputs":[],"source":["# handle employment_type - keep na values as unknown\n","df['employment_type'] = df['employment_type'].fillna('Unknown')\n","\n","# keep track in cols_to_keep and cols_to_drop\n","cols_to_keep.append('employment_type')"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34,"status":"ok","timestamp":1700654019228,"user":{"displayName":"lo zh","userId":"05866467891459786403"},"user_tz":-480},"id":"zH1zgkRzmlC8","outputId":"a8c92c1a-815d-469d-b24f-dc01786b71e9"},"outputs":[{"data":{"text/plain":["array(['Internship', 'Not Applicable', nan, 'Mid-Senior level',\n","       'Associate', 'Entry level', 'Executive', 'Director'], dtype=object)"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["df['required_experience'].unique()"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":33,"status":"ok","timestamp":1700654019228,"user":{"displayName":"lo zh","userId":"05866467891459786403"},"user_tz":-480},"id":"zWagbNEEnSun"},"outputs":[],"source":["# handle required_experience - keep na values as unknown\n","df['required_experience'] = df['required_experience'].fillna('Unknown')\n","\n","# keep track in cols_to_keep and cols_to_drop\n","cols_to_keep.append('required_experience')"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33,"status":"ok","timestamp":1700654019229,"user":{"displayName":"lo zh","userId":"05866467891459786403"},"user_tz":-480},"id":"8-49WtjqnBg0","outputId":"292dc087-48e7-4328-bbbf-bdb0f1b2aecd"},"outputs":[{"data":{"text/plain":["array([nan, \"Bachelor's Degree\", \"Master's Degree\",\n","       'High School or equivalent', 'Unspecified',\n","       'Some College Coursework Completed', 'Vocational', 'Certification',\n","       'Associate Degree', 'Professional', 'Doctorate',\n","       'Some High School Coursework', 'Vocational - Degree',\n","       'Vocational - HS Diploma'], dtype=object)"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["df['required_education'].unique()"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":32,"status":"ok","timestamp":1700654019229,"user":{"displayName":"lo zh","userId":"05866467891459786403"},"user_tz":-480},"id":"hXEmMWObnW-A"},"outputs":[],"source":["# handle required_education - keep na values as unknown\n","df['required_education'] = df['required_education'].fillna('Unknown')\n","\n","# keep track in cols_to_keep and cols_to_drop\n","cols_to_keep.append('required_education')"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31,"status":"ok","timestamp":1700654019229,"user":{"displayName":"lo zh","userId":"05866467891459786403"},"user_tz":-480},"id":"plEO6RFlntPE","outputId":"b4b479bf-fc14-46c5-9fe1-5b10b29ed33c"},"outputs":[{"data":{"text/plain":["['country',\n"," 'city',\n"," 'has_description',\n"," 'has_department',\n"," 'has_salary',\n"," 'has_company_profile',\n"," 'has_requirements',\n"," 'has_benefits',\n"," 'employment_type',\n"," 'required_experience',\n"," 'required_education']"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["cols_to_keep"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":29,"status":"ok","timestamp":1700654019229,"user":{"displayName":"lo zh","userId":"05866467891459786403"},"user_tz":-480},"id":"raeV5ycOntRw"},"outputs":[],"source":["# handle industry - keep the industries - fillna with unknown\n","df['industry'] = df['industry'].fillna('Unknown')\n","\n","# a lot of sparse values noted for industries, may lead to unexpected results - to handle - keep countries with counts >10 only and put unknown for the rest\n","ls_of_industries = [industry if df[df['industry']==industry]['industry'].count() >= 10 else 'NA' for industry in df['industry'].unique()]\n","df['industry'] = df['industry'].apply(lambda x : x if x in ls_of_industries else 'Unknown')\n","\n","# keep track in cols_to_keep and cols_to_drop\n","cols_to_keep.append('industry')"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":28,"status":"ok","timestamp":1700654019229,"user":{"displayName":"lo zh","userId":"05866467891459786403"},"user_tz":-480},"id":"s0R5bJAZntUG"},"outputs":[],"source":["# handle function - keep the functions - fillna with unknown\n","df['function'] = df['function'].fillna('Unknown')\n","\n","# keep track in cols_to_keep and cols_to_drop\n","cols_to_keep.append('function')"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1700654019230,"user":{"displayName":"lo zh","userId":"05866467891459786403"},"user_tz":-480},"id":"e2zSWDa2poYt","outputId":"cdf9d9ac-ac63-41aa-f80e-61c0bb4a9368"},"outputs":[{"data":{"text/plain":["['country',\n"," 'city',\n"," 'has_description',\n"," 'has_department',\n"," 'has_salary',\n"," 'has_company_profile',\n"," 'has_requirements',\n"," 'has_benefits',\n"," 'employment_type',\n"," 'required_experience',\n"," 'required_education',\n"," 'industry',\n"," 'function']"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["cols_to_keep"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1700654019230,"user":{"displayName":"lo zh","userId":"05866467891459786403"},"user_tz":-480},"id":"AbCxBa_0pobb","outputId":"5cf1510f-ecec-423d-bd50-448a2483d314"},"outputs":[{"data":{"text/plain":["['location', 'description', 'salary_range']"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["cols_to_drop"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["# fill up the null values with - no available data \n","df[['company_profile' , 'description','requirements','benefits']] = df[['company_profile' , 'description','requirements','benefits']].fillna('no available data')"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["# create new feature - job_field - based on the title, dept, industry and function\n","df['job_field'] = df['title'] +' '+ df['department'] +' '+ df['industry'] +' '+ df['function']\n","df['job_field'] = df['job_field'].fillna('No available data')\n","df.drop(['title','department'] , axis = 1 , inplace = True )"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"data":{"text/plain":["Index(['job_id', 'location', 'salary_range', 'company_profile', 'description',\n","       'requirements', 'benefits', 'telecommuting', 'has_company_logo',\n","       'has_questions', 'employment_type', 'required_experience',\n","       'required_education', 'industry', 'function', 'fraudulent', 'country',\n","       'city', 'has_description', 'has_department', 'has_salary',\n","       'has_company_profile', 'has_requirements', 'has_benefits', 'job_field'],\n","      dtype='object')"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["df.columns"]},{"cell_type":"markdown","metadata":{"id":"ww1pTUcmqECs"},"source":["## Next we look into the non null columns to extract what we wanna keep"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1700654019230,"user":{"displayName":"lo zh","userId":"05866467891459786403"},"user_tz":-480},"id":"3IeRjavnqOtQ"},"outputs":[],"source":["# drop the cols inside cols_to_drop as it is not useful anymore\n","df = df.drop(cols_to_drop, axis=1)"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1700654019230,"user":{"displayName":"lo zh","userId":"05866467891459786403"},"user_tz":-480},"id":"SyCGkTnqqZna"},"outputs":[],"source":["cols_to_drop = []"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1700654019231,"user":{"displayName":"lo zh","userId":"05866467891459786403"},"user_tz":-480},"id":"TctdijreqA74","outputId":"02d90ce5-c420-426a-a80c-8f6336af95b1"},"outputs":[{"data":{"text/plain":["job_id                 0\n","company_profile        0\n","requirements           0\n","benefits               0\n","telecommuting          0\n","has_company_logo       0\n","has_questions          0\n","employment_type        0\n","required_experience    0\n","required_education     0\n","industry               0\n","function               0\n","fraudulent             0\n","country                0\n","city                   0\n","has_description        0\n","has_department         0\n","has_salary             0\n","has_company_profile    0\n","has_requirements       0\n","has_benefits           0\n","job_field              0\n","dtype: int64"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["df.isna().sum()"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1700654019231,"user":{"displayName":"lo zh","userId":"05866467891459786403"},"user_tz":-480},"id":"wwR-pVbIqfx1"},"outputs":[],"source":["# handle job_id - it is unique for all - so not much value - remove the col\n","df = df.drop('job_id', axis=1)"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1700654019231,"user":{"displayName":"lo zh","userId":"05866467891459786403"},"user_tz":-480},"id":"gvf12NGyqxtN"},"outputs":[],"source":["# handle telecommuting, has_company_logo, has_questions - all are binary - keep as features\n","# keep track in cols_to_keep\n","cols_to_keep.append('telecommuting')\n","cols_to_keep.append('has_company_logo')\n","cols_to_keep.append('has_questions')"]},{"cell_type":"markdown","metadata":{"id":"E-ovUwRVsMBX"},"source":["And with that all the columns are processed accordingly, except the text features that are going to be used for text processing"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1700654019232,"user":{"displayName":"lo zh","userId":"05866467891459786403"},"user_tz":-480},"id":"Smm0MNZpsPNu","outputId":"cbfe39cc-a35f-4b05-dd5f-72225420a3e6"},"outputs":[{"data":{"text/plain":["['country',\n"," 'city',\n"," 'has_description',\n"," 'has_department',\n"," 'has_salary',\n"," 'has_company_profile',\n"," 'has_requirements',\n"," 'has_benefits',\n"," 'employment_type',\n"," 'required_experience',\n"," 'required_education',\n"," 'industry',\n"," 'function',\n"," 'telecommuting',\n"," 'has_company_logo',\n"," 'has_questions']"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["cols_to_keep"]},{"cell_type":"markdown","metadata":{"id":"oTovCBTkAXxU"},"source":["## Text Processing - including the text information into the model\n","\n","This is referred from an implementation by AbulRahman, from the github repo - https://github.com/AbdulrahmenSalem/Text-Preprocessing\n","\n","Details can be found on the github page, together with the README file explaining the methodologies."]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["# !pip install nltk # install package if still not installed"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1001,"status":"ok","timestamp":1700654020219,"user":{"displayName":"lo zh","userId":"05866467891459786403"},"user_tz":-480},"id":"d5K1XtgxAXG7","outputId":"fe1608d3-5e98-411b-9b46-946ea4e0d04c"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\Jason\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to\n","[nltk_data]     C:\\Users\\Jason\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to\n","[nltk_data]     C:\\Users\\Jason\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n"]}],"source":["# import relevant packages\n","import nltk\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","nltk.download('omw-1.4')\n","\n","import re\n","from nltk.corpus import stopwords \n","import string \n","from nltk.stem import WordNetLemmatizer\n","punc = string.punctuation\n","lmt = WordNetLemmatizer()\n","s_words = stopwords.words('english')"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1700654020220,"user":{"displayName":"lo zh","userId":"05866467891459786403"},"user_tz":-480},"id":"JwPF78IrAkgQ"},"outputs":[],"source":["# taken from the github repo\n","class TextPreprocessing() :\n","    def __init__(self, df : pd.DataFrame = pd.DataFrame) :\n","        self.df = df\n","        \n","        \n","    def Clean(self , df) :\n","        self.df = df\n","        df_copy = df.copy(deep = True)\n","        text_cols = list(df_copy.select_dtypes(include = ['object']).columns)\n","        for col in text_cols :\n","            for idx, text in enumerate(df_copy[col]) :\n","                te = []\n","                word = re.sub(r'(@|#)\\w+' , '' , text)\n","                word = re.sub(\"[,.]\", \"\", word)\n","                word = re.sub(r'https?://\\S+' , '' , word)\n","                word = re.sub(r'(\\?|!)+' , '' , word)\n","                word = re.sub(r\"\\(|\\)\", \"\", word)\n","                word = re.sub(r'(^\\s+)' , '' , word)\n","                word = re.sub(r'(\\s+$)' , '' , word)\n","                word = re.sub(r'\\d+' , '' , word)\n","                word = word.split()\n","                for i in word :\n","                    if (i not in s_words) & (i not in punc) :\n","                        i = i.lower()\n","                        i = lmt.lemmatize(i , 'v')\n","                        te.append(i)\n","                df_copy.at[idx , col] = te\n","        return df_copy\n","    \n","    def Vactorize (self, df , target_name) :\n","        self.df = df\n","        self.target_name = target_name\n","        df_cleaned = df.copy(deep = True)\n","        text_cols = list(df_cleaned.select_dtypes(include = ['object']).columns)\n","        pos_word = {}\n","        neg_word = {}\n","\n","        pos_df = df_cleaned[df_cleaned[target_name] == 1].reset_index(drop=True)\n","        neg_df = df_cleaned[df_cleaned[target_name] == 0].reset_index(drop=True)\n","        \n","        for col in text_cols :\n","\n","            pos_word[col] = [word for sublist in pos_df[col] for word in sublist]\n","            neg_word[col] = [word for sublist in neg_df[col] for word in sublist]\n","\n","\n","\n","        pos_freq = {}\n","        neg_freq = {}\n","        for key in pos_word.keys() :\n","            positive_dict = {}\n","            for word in pos_word[key] :\n","                positive_dict[word] = positive_dict.get(word , 0) + 1\n","\n","            pos_freq[key] = positive_dict\n","\n","\n","        for key in neg_word.keys() :\n","            negative_dict = {}\n","            for word in neg_word[key] :\n","                negative_dict[word] = negative_dict.get(word , 0) + 1\n","\n","            neg_freq[key] = negative_dict\n","            \n","        return pos_freq , neg_freq\n","\n","        \n","        \n","        \n","    def Vactorization (self , df , target_name) :\n","        self.df = df\n","        self.target_name = target_name\n","        df_cleaned = df.copy(deep = True)\n","        text_cols = list(df_cleaned.select_dtypes(include = ['object']).columns)\n","        pos_freq , neg_freq = TextPreprocessing().Vactorize(df_cleaned , target_name)\n","\n","        for col in text_cols :\n","            df_cleaned['{}_pos'.format(col)] = 0\n","            df_cleaned['{}_neg'.format(col)] = 0\n","            for idx, List in enumerate(df_cleaned[col]) :\n","                pos_frequent = 0\n","                neg_frequent = 0\n","                for word in List :\n","                    pos_frequent += pos_freq[col].get(word , 0)\n","                    neg_frequent += neg_freq[col].get(word , 0)\n","\n","\n","\n","                df_cleaned.at[idx ,'{}_pos'.format(col)] = pos_frequent\n","                df_cleaned.at[idx ,'{}_neg'.format(col)] = neg_frequent\n","            df_cleaned.drop([col] , axis = 1 , inplace = True)\n","        return df_cleaned\n","    \n","    \n","    def fit_transform(self , df , target_name) :\n","        self.df = df\n","        self.target_name = target_name\n","        \n","        df_cleaned = TextPreprocessing().Clean(df)\n","        df_vact = TextPreprocessing().Vactorization(df_cleaned , target_name)\n","        \n","        return df_vact\n","    \n","    \n","    def Naive_Bayes(self , df, target_name) :\n","        self.df = df\n","        self.target_name = target_name\n","        df_naive = TextPreprocessing().Clean(df)\n","        pos_freq , neg_freq = TextPreprocessing().Vactorize(df_naive , target_name)\n","        text_cols = list(df_naive.select_dtypes(include = ['object']).columns)\n","        \n","        v_n_pos , v_n_neg = {} , {}\n","\n","        for key in pos_freq.keys() :\n","            v_n_pos[key] = len(pos_freq[key])\n","            n = 0\n","            for word in pos_freq[key] :\n","                n += pos_freq[key].get(word , 0)\n","            v_n_pos[key]+=n\n","        for key in neg_freq.keys() :\n","            v_n_neg[key] = len(neg_freq[key])\n","            n = 0\n","            for word in neg_freq[key] :\n","                n += neg_freq[key].get(word , 0)\n","            v_n_neg[key]+=n\n","            \n","            \n","        prob_pos_dict = {}\n","        for key in pos_freq.keys():\n","            positive_dict = {}\n","            for word in pos_freq[key] :\n","                positive_dict[word] = (pos_freq[key].get(word , 0) + 1) / (v_n_pos[key])\n","            prob_pos_dict[key] = positive_dict\n","\n","\n","\n","\n","        prob_neg_dict = {}\n","        for key in neg_freq.keys():\n","            negative_dict = {}\n","            for word in neg_freq[key] :\n","                negative_dict[word] = (neg_freq[key].get(word , 0) + 1) / (v_n_neg[key])\n","            prob_neg_dict[key] = negative_dict\n","            \n","            \n","            \n","        for col in text_cols :\n","            df_naive['{}_probs'.format(col)] = 0\n","            for idx, List in enumerate(df_naive[col]) :\n","                score = 0\n","                for word in List :\n","                    try :\n","                        # b = np.log((prob_pos_dict[col].get(word , 0)) / (prob_neg_dict[col].get(word , 0)))\n","                        if (prob_neg_dict[col].get(word , 0)) != 0:\n","                            b = np.log((prob_pos_dict[col].get(word , 0)) / (prob_neg_dict[col].get(word , 0)))  \n","                        else:\n","                            # Handle the case where neg_word_prob is zero\n","                            # # You can set a default value or handle it based on your use case\n","                            b = np.log((prob_pos_dict[col].get(word , 0))) if (prob_pos_dict[col].get(word , 0)) != 0 else 0\n","                        if b == -float('inf') :\n","                            pass\n","                        else :\n","                            score +=b\n","                    except :\n","                        pass\n","\n","                df_naive['{}_probs'.format(col)][idx] = score\n","            df_naive.drop([col] , axis = 1 , inplace = True)\n","            \n","            \n","        return {'probs_pos':prob_pos_dict ,'probs_neg':prob_neg_dict } , df_naive  "]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 17880 entries, 0 to 17879\n","Data columns (total 21 columns):\n"," #   Column               Non-Null Count  Dtype \n","---  ------               --------------  ----- \n"," 0   company_profile      17880 non-null  object\n"," 1   requirements         17880 non-null  object\n"," 2   benefits             17880 non-null  object\n"," 3   telecommuting        17880 non-null  int64 \n"," 4   has_company_logo     17880 non-null  int64 \n"," 5   has_questions        17880 non-null  int64 \n"," 6   employment_type      17880 non-null  object\n"," 7   required_experience  17880 non-null  object\n"," 8   required_education   17880 non-null  object\n"," 9   industry             17880 non-null  object\n"," 10  function             17880 non-null  object\n"," 11  fraudulent           17880 non-null  int64 \n"," 12  country              17880 non-null  object\n"," 13  city                 17880 non-null  object\n"," 14  has_description      17880 non-null  int64 \n"," 15  has_department       17880 non-null  object\n"," 16  has_salary           17880 non-null  int64 \n"," 17  has_company_profile  17880 non-null  int64 \n"," 18  has_requirements     17880 non-null  int64 \n"," 19  has_benefits         17880 non-null  int64 \n"," 20  job_field            17880 non-null  object\n","dtypes: int64(9), object(12)\n","memory usage: 2.9+ MB\n"]}],"source":["df.info()"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>company_profile</th>\n","      <th>requirements</th>\n","      <th>benefits</th>\n","      <th>telecommuting</th>\n","      <th>has_company_logo</th>\n","      <th>has_questions</th>\n","      <th>employment_type</th>\n","      <th>required_experience</th>\n","      <th>required_education</th>\n","      <th>industry</th>\n","      <th>...</th>\n","      <th>fraudulent</th>\n","      <th>country</th>\n","      <th>city</th>\n","      <th>has_description</th>\n","      <th>has_department</th>\n","      <th>has_salary</th>\n","      <th>has_company_profile</th>\n","      <th>has_requirements</th>\n","      <th>has_benefits</th>\n","      <th>job_field</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[we're, food, we've, create, groundbreaking, a...</td>\n","      <td>[experience, content, management, systems, maj...</td>\n","      <td>[available, data]</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>[other]</td>\n","      <td>[internship]</td>\n","      <td>[unknown]</td>\n","      <td>[unknown]</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>[us]</td>\n","      <td>[new, york]</td>\n","      <td>1</td>\n","      <td>[market]</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>[market, intern, market, unknown, market]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[second, worlds, cloud, video, production, ser...</td>\n","      <td>[what, expect, you:your, key, responsibility, ...</td>\n","      <td>[what, get, usthrough, part, second, team, gai...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>[full-time]</td>\n","      <td>[not, applicable]</td>\n","      <td>[unknown]</td>\n","      <td>[market, advertise]</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>[nz]</td>\n","      <td>[auckland]</td>\n","      <td>1</td>\n","      <td>[unknown]</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>[customer, service, cloud, video, production, ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>[valor, service, provide, workforce, solutions...</td>\n","      <td>[implement, pre-commissioning, commission, pro...</td>\n","      <td>[available, data]</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>[unknown]</td>\n","      <td>[unknown]</td>\n","      <td>[unknown]</td>\n","      <td>[unknown]</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>[us]</td>\n","      <td>[unknown]</td>\n","      <td>1</td>\n","      <td>[unknown]</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>[no, available, data]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[our, passion, improve, quality, life, geograp...</td>\n","      <td>[education:, bachelor’s, master’s, gi, busines...</td>\n","      <td>[our, culture, anything, corporate—we, collabo...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>[full-time]</td>\n","      <td>[mid-senior, level]</td>\n","      <td>[bachelor's, degree]</td>\n","      <td>[computer, software]</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>[us]</td>\n","      <td>[washington]</td>\n","      <td>1</td>\n","      <td>[sales]</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>[account, executive, washington, dc, sales, co...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[spotsource, solutions, llc, global, human, ca...</td>\n","      <td>[qualifications:rn, license, state, texasdiplo...</td>\n","      <td>[full, benefit, offer]</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>[full-time]</td>\n","      <td>[mid-senior, level]</td>\n","      <td>[bachelor's, degree]</td>\n","      <td>[hospital, health, care]</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>[us]</td>\n","      <td>[fort, worth]</td>\n","      <td>1</td>\n","      <td>[unknown]</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>[no, available, data]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 21 columns</p>\n","</div>"],"text/plain":["                                     company_profile  \\\n","0  [we're, food, we've, create, groundbreaking, a...   \n","1  [second, worlds, cloud, video, production, ser...   \n","2  [valor, service, provide, workforce, solutions...   \n","3  [our, passion, improve, quality, life, geograp...   \n","4  [spotsource, solutions, llc, global, human, ca...   \n","\n","                                        requirements  \\\n","0  [experience, content, management, systems, maj...   \n","1  [what, expect, you:your, key, responsibility, ...   \n","2  [implement, pre-commissioning, commission, pro...   \n","3  [education:, bachelor’s, master’s, gi, busines...   \n","4  [qualifications:rn, license, state, texasdiplo...   \n","\n","                                            benefits  telecommuting  \\\n","0                                  [available, data]              0   \n","1  [what, get, usthrough, part, second, team, gai...              0   \n","2                                  [available, data]              0   \n","3  [our, culture, anything, corporate—we, collabo...              0   \n","4                             [full, benefit, offer]              0   \n","\n","   has_company_logo  has_questions employment_type  required_experience  \\\n","0                 1              0         [other]         [internship]   \n","1                 1              0     [full-time]    [not, applicable]   \n","2                 1              0       [unknown]            [unknown]   \n","3                 1              0     [full-time]  [mid-senior, level]   \n","4                 1              1     [full-time]  [mid-senior, level]   \n","\n","     required_education                  industry  ... fraudulent  country  \\\n","0             [unknown]                 [unknown]  ...          0     [us]   \n","1             [unknown]       [market, advertise]  ...          0     [nz]   \n","2             [unknown]                 [unknown]  ...          0     [us]   \n","3  [bachelor's, degree]      [computer, software]  ...          0     [us]   \n","4  [bachelor's, degree]  [hospital, health, care]  ...          0     [us]   \n","\n","            city has_description  has_department has_salary  \\\n","0    [new, york]               1        [market]          0   \n","1     [auckland]               1       [unknown]          0   \n","2      [unknown]               1       [unknown]          0   \n","3   [washington]               1         [sales]          0   \n","4  [fort, worth]               1       [unknown]          0   \n","\n","   has_company_profile  has_requirements  has_benefits  \\\n","0                    1                 1             0   \n","1                    1                 1             1   \n","2                    1                 1             0   \n","3                    1                 1             1   \n","4                    1                 1             1   \n","\n","                                           job_field  \n","0          [market, intern, market, unknown, market]  \n","1  [customer, service, cloud, video, production, ...  \n","2                              [no, available, data]  \n","3  [account, executive, washington, dc, sales, co...  \n","4                              [no, available, data]  \n","\n","[5 rows x 21 columns]"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["# cleaning text - check the performance of the function\n","pre = TextPreprocessing()\n","df_cleaned = pre.Clean(df)\n","df_cleaned.head()"]},{"cell_type":"markdown","metadata":{"id":"xIAA4pArshLy"},"source":["## Train-test split and preprocessing before inputting into model"]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1700654480430,"user":{"displayName":"lo zh","userId":"05866467891459786403"},"user_tz":-480},"id":"H0wLWq1vsgvF"},"outputs":[],"source":["# seperate out the correctly formatted cols and those which still needs processing through ohe\n","binary_cols = ['has_description', 'has_salary', 'has_company_profile', 'has_requirements', 'has_benefits', 'telecommuting', 'has_company_logo', 'has_questions']"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1700654480431,"user":{"displayName":"lo zh","userId":"05866467891459786403"},"user_tz":-480},"id":"ab53_ucMsQ54"},"outputs":[],"source":["# select the fraudulent column as target, rest as features\n","nontext_features = df[binary_cols]\n","text_features = df.drop(binary_cols, axis=1)\n","target_var = df['fraudulent']"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":461},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1700654480431,"user":{"displayName":"lo zh","userId":"05866467891459786403"},"user_tz":-480},"id":"vbQTRou4uClH","outputId":"e2d9fa2e-f61c-463e-e489-7bc17929df68"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>has_description</th>\n","      <th>has_salary</th>\n","      <th>has_company_profile</th>\n","      <th>has_requirements</th>\n","      <th>has_benefits</th>\n","      <th>telecommuting</th>\n","      <th>has_company_logo</th>\n","      <th>has_questions</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>17875</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>17876</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>17877</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>17878</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>17879</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>17880 rows × 8 columns</p>\n","</div>"],"text/plain":["       has_description  has_salary  has_company_profile  has_requirements  \\\n","0                    1           0                    1                 1   \n","1                    1           0                    1                 1   \n","2                    1           0                    1                 1   \n","3                    1           0                    1                 1   \n","4                    1           0                    1                 1   \n","...                ...         ...                  ...               ...   \n","17875                1           0                    1                 1   \n","17876                1           0                    1                 1   \n","17877                1           0                    1                 1   \n","17878                1           0                    0                 1   \n","17879                1           0                    1                 1   \n","\n","       has_benefits  telecommuting  has_company_logo  has_questions  \n","0                 0              0                 1              0  \n","1                 1              0                 1              0  \n","2                 0              0                 1              0  \n","3                 1              0                 1              0  \n","4                 1              0                 1              1  \n","...             ...            ...               ...            ...  \n","17875             1              0                 1              1  \n","17876             1              0                 1              1  \n","17877             0              0                 0              0  \n","17878             1              0                 0              1  \n","17879             0              0                 1              1  \n","\n","[17880 rows x 8 columns]"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["nontext_features # check the colummns if its in correct format"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>fraudulent</th>\n","      <th>company_profile_pos</th>\n","      <th>company_profile_neg</th>\n","      <th>requirements_pos</th>\n","      <th>requirements_neg</th>\n","      <th>benefits_pos</th>\n","      <th>benefits_neg</th>\n","      <th>employment_type_pos</th>\n","      <th>employment_type_neg</th>\n","      <th>required_experience_pos</th>\n","      <th>...</th>\n","      <th>function_pos</th>\n","      <th>function_neg</th>\n","      <th>country_pos</th>\n","      <th>country_neg</th>\n","      <th>city_pos</th>\n","      <th>city_neg</th>\n","      <th>has_department_pos</th>\n","      <th>has_department_neg</th>\n","      <th>job_field_pos</th>\n","      <th>job_field_neg</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>11270784</td>\n","      <td>606587132</td>\n","      <td>19429133</td>\n","      <td>515095602</td>\n","      <td>197602</td>\n","      <td>4053003</td>\n","      <td>1489</td>\n","      <td>31369</td>\n","      <td>5343</td>\n","      <td>...</td>\n","      <td>5491</td>\n","      <td>103000</td>\n","      <td>1502</td>\n","      <td>20295</td>\n","      <td>3213</td>\n","      <td>68530</td>\n","      <td>4102</td>\n","      <td>73297</td>\n","      <td>83954</td>\n","      <td>1485278</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>13306514</td>\n","      <td>704224601</td>\n","      <td>31979118</td>\n","      <td>847867195</td>\n","      <td>14371401</td>\n","      <td>289667528</td>\n","      <td>5956</td>\n","      <td>130630</td>\n","      <td>4669</td>\n","      <td>...</td>\n","      <td>6819</td>\n","      <td>132770</td>\n","      <td>31</td>\n","      <td>1579</td>\n","      <td>2975</td>\n","      <td>65928</td>\n","      <td>9672</td>\n","      <td>184912</td>\n","      <td>158297</td>\n","      <td>2768207</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>11358183</td>\n","      <td>613339938</td>\n","      <td>31829212</td>\n","      <td>840638076</td>\n","      <td>197602</td>\n","      <td>4053003</td>\n","      <td>3311</td>\n","      <td>48149</td>\n","      <td>6823</td>\n","      <td>...</td>\n","      <td>7054</td>\n","      <td>136495</td>\n","      <td>1502</td>\n","      <td>20295</td>\n","      <td>5304</td>\n","      <td>101676</td>\n","      <td>9672</td>\n","      <td>184912</td>\n","      <td>42227</td>\n","      <td>798666</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>7536251</td>\n","      <td>405332317</td>\n","      <td>33324591</td>\n","      <td>882395140</td>\n","      <td>8291316</td>\n","      <td>168197205</td>\n","      <td>5956</td>\n","      <td>130630</td>\n","      <td>8402</td>\n","      <td>...</td>\n","      <td>1640</td>\n","      <td>37139</td>\n","      <td>1502</td>\n","      <td>20295</td>\n","      <td>4742</td>\n","      <td>102757</td>\n","      <td>639</td>\n","      <td>10586</td>\n","      <td>109316</td>\n","      <td>1951947</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>19441412</td>\n","      <td>1037924710</td>\n","      <td>16597448</td>\n","      <td>439291440</td>\n","      <td>201135</td>\n","      <td>4061246</td>\n","      <td>5956</td>\n","      <td>130630</td>\n","      <td>8402</td>\n","      <td>...</td>\n","      <td>7337</td>\n","      <td>152750</td>\n","      <td>1502</td>\n","      <td>20295</td>\n","      <td>3497</td>\n","      <td>78682</td>\n","      <td>9672</td>\n","      <td>184912</td>\n","      <td>42227</td>\n","      <td>798666</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 25 columns</p>\n","</div>"],"text/plain":["   fraudulent  company_profile_pos  company_profile_neg  requirements_pos  \\\n","0           0             11270784            606587132          19429133   \n","1           0             13306514            704224601          31979118   \n","2           0             11358183            613339938          31829212   \n","3           0              7536251            405332317          33324591   \n","4           0             19441412           1037924710          16597448   \n","\n","   requirements_neg  benefits_pos  benefits_neg  employment_type_pos  \\\n","0         515095602        197602       4053003                 1489   \n","1         847867195      14371401     289667528                 5956   \n","2         840638076        197602       4053003                 3311   \n","3         882395140       8291316     168197205                 5956   \n","4         439291440        201135       4061246                 5956   \n","\n","   employment_type_neg  required_experience_pos  ...  function_pos  \\\n","0                31369                     5343  ...          5491   \n","1               130630                     4669  ...          6819   \n","2                48149                     6823  ...          7054   \n","3               130630                     8402  ...          1640   \n","4               130630                     8402  ...          7337   \n","\n","   function_neg  country_pos  country_neg  city_pos  city_neg  \\\n","0        103000         1502        20295      3213     68530   \n","1        132770           31         1579      2975     65928   \n","2        136495         1502        20295      5304    101676   \n","3         37139         1502        20295      4742    102757   \n","4        152750         1502        20295      3497     78682   \n","\n","   has_department_pos  has_department_neg  job_field_pos  job_field_neg  \n","0                4102               73297          83954        1485278  \n","1                9672              184912         158297        2768207  \n","2                9672              184912          42227         798666  \n","3                 639               10586         109316        1951947  \n","4                9672              184912          42227         798666  \n","\n","[5 rows x 25 columns]"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["# use Count vectorizer to generate probabilities and values for text data\n","df_cleaned = pre.Vactorization(text_features , target_name = 'fraudulent')\n","df_cleaned.head()"]},{"cell_type":"code","execution_count":40,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1700654480432,"user":{"displayName":"lo zh","userId":"05866467891459786403"},"user_tz":-480},"id":"sITloC9QuH0h"},"outputs":[],"source":["# # train test split\n","# from sklearn.model_selection import train_test_split\n","\n","# xtrain, xtest, ytrain, ytest = train_test_split(features_encoded, target_var, random_state=0, test_size=0.2)"]},{"cell_type":"code","execution_count":41,"metadata":{"executionInfo":{"elapsed":2671,"status":"ok","timestamp":1700654483091,"user":{"displayName":"lo zh","userId":"05866467891459786403"},"user_tz":-480},"id":"59BZf_UOIzp6"},"outputs":[],"source":["# train test split v2 - with text features included\n","from sklearn.model_selection import train_test_split\n","\n","# concat text features and ohe encoded features\n","text_df = df_cleaned.drop('fraudulent', axis=1)\n","features_concated = pd.concat([nontext_features, text_df], axis=1)\n","\n","# train test split\n","xtrain, xtest, ytrain, ytest = train_test_split(features_concated, target_var, random_state=0, test_size=0.2)"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","x_train = scaler.fit_transform(xtrain)\n","x_test = scaler.transform(xtest)"]},{"cell_type":"markdown","metadata":{"id":"iNugMSBjuwBB"},"source":["## Model training - Random Forest, XGBoost, Logistic Regression, Support vector machines"]},{"cell_type":"code","execution_count":43,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1700654483091,"user":{"displayName":"lo zh","userId":"05866467891459786403"},"user_tz":-480},"id":"5KMdJwrQwCvb"},"outputs":[],"source":["# model packages\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import make_scorer, f1_score\n","from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, classification_report\n","from xgboost import XGBClassifier"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20327,"status":"ok","timestamp":1700654503414,"user":{"displayName":"lo zh","userId":"05866467891459786403"},"user_tz":-480},"id":"SVMYwp7yuxt3","outputId":"0d799429-ca46-4bbe-9203-0e895730df61"},"outputs":[{"name":"stdout","output_type":"stream","text":["Random Forest Classifier:\n","Accuracy: 0.9821029082774049\n","\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.98      1.00      0.99      3423\n","           1       0.93      0.63      0.75       153\n","\n","    accuracy                           0.98      3576\n","   macro avg       0.96      0.81      0.87      3576\n","weighted avg       0.98      0.98      0.98      3576\n","\n","Confusion Matrix:\n","[[3416    7]\n"," [  57   96]]\n","Accuracy: 0.9821029082774049\n","Precision: 0.9320388349514563\n","Recall: 0.6274509803921569\n","F1 Score: 0.75\n"]}],"source":["# model training - Random Forest\n","# train model\n","rfc = RandomForestClassifier(random_state=0)\n","xtrain.columns = xtrain.columns.astype(str) # keep column name\n","rfc.fit(xtrain, ytrain)\n","\n","# predictions\n","xtest.columns = xtest.columns.astype(str) # keep column name\n","rfc_ypred = rfc.predict(xtest)\n","\n","# Evaluate the Random Forest model\n","print(\"Random Forest Classifier:\")\n","print(\"Accuracy:\", accuracy_score(ytest, rfc_ypred))\n","print(\"\\nClassification Report:\\n\", classification_report(ytest, rfc_ypred))\n","\n","# Assuming y_true and y_pred are your true labels and predicted labels\n","conf_matrix = confusion_matrix(ytest, rfc_ypred)\n","\n","# Calculate evaluation metrics\n","accuracy = accuracy_score(ytest, rfc_ypred)\n","precision = precision_score(ytest, rfc_ypred)\n","recall = recall_score(ytest, rfc_ypred)\n","f1 = f1_score(ytest, rfc_ypred)\n","\n","# Display the confusion matrix and metrics\n","print(\"Confusion Matrix:\")\n","print(conf_matrix)\n","print(\"Accuracy:\", accuracy)\n","print(\"Precision:\", precision)\n","print(\"Recall:\", recall)\n","print(\"F1 Score:\", f1)"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12395,"status":"ok","timestamp":1700654515773,"user":{"displayName":"lo zh","userId":"05866467891459786403"},"user_tz":-480},"id":"giN_MIJXvIJr","outputId":"069b71be-df45-48a0-d9a9-a7043cc89fa9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Logistic Regression:\n","Accuracy: 0.9580536912751678\n","\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.96      1.00      0.98      3423\n","           1       0.67      0.04      0.07       153\n","\n","    accuracy                           0.96      3576\n","   macro avg       0.81      0.52      0.53      3576\n","weighted avg       0.95      0.96      0.94      3576\n","\n","Confusion Matrix:\n","[[3420    3]\n"," [ 147    6]]\n","Accuracy: 0.9580536912751678\n","Precision: 0.6666666666666666\n","Recall: 0.0392156862745098\n","F1 Score: 0.07407407407407407\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\Jason\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]}],"source":["# model training - logistic regression\n","# train model\n","lr = LogisticRegression(random_state=0)\n","xtrain.columns = xtrain.columns.astype(str) # keep column name\n","lr.fit(xtrain, ytrain)\n","\n","# predictions\n","xtest.columns = xtest.columns.astype(str) # keep column name\n","lr_ypred = lr.predict(xtest)\n","\n","# Evaluate the logistic regression model\n","print(\"Logistic Regression:\")\n","print(\"Accuracy:\", accuracy_score(ytest, lr_ypred))\n","print(\"\\nClassification Report:\\n\", classification_report(ytest, lr_ypred))\n","\n","# Assuming y_true and y_pred are your true labels and predicted labels\n","conf_matrix = confusion_matrix(ytest, lr_ypred)\n","\n","# Calculate evaluation metrics\n","accuracy = accuracy_score(ytest, lr_ypred)\n","precision = precision_score(ytest, lr_ypred)\n","recall = recall_score(ytest, lr_ypred)\n","f1 = f1_score(ytest, lr_ypred)\n","\n","# Display the confusion matrix and metrics\n","print(\"Confusion Matrix:\")\n","print(conf_matrix)\n","print(\"Accuracy:\", accuracy)\n","print(\"Precision:\", precision)\n","print(\"Recall:\", recall)\n","print(\"F1 Score:\", f1)"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":58468,"status":"ok","timestamp":1700654574234,"user":{"displayName":"lo zh","userId":"05866467891459786403"},"user_tz":-480},"id":"J32rxDEvLcb0","outputId":"a42a58cc-16ba-45ae-c8f3-db0abf1c77cd"},"outputs":[{"name":"stdout","output_type":"stream","text":["XGBoost:\n","Accuracy: 0.985738255033557\n","\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.99      1.00      0.99      3423\n","           1       0.95      0.71      0.81       153\n","\n","    accuracy                           0.99      3576\n","   macro avg       0.97      0.85      0.90      3576\n","weighted avg       0.99      0.99      0.98      3576\n","\n","Confusion Matrix:\n","[[3417    6]\n"," [  45  108]]\n","Accuracy: 0.985738255033557\n","Precision: 0.9473684210526315\n","Recall: 0.7058823529411765\n","F1 Score: 0.8089887640449439\n"]}],"source":["# model training - xgboost\n","# Create an instance of XGBClassifier\n","xgb_classifier = XGBClassifier(random_state=0)\n","xtrain.columns = xtrain.columns.astype(str) # keep column name\n","xgb_classifier.fit(xtrain, ytrain)\n","\n","# Make predictions on the test set\n","xtest.columns = xtest.columns.astype(str) # keep column name\n","xgb_ypred = xgb_classifier.predict(xtest)\n","\n","# Evaluate the logistic regression model\n","print(\"XGBoost:\")\n","print(\"Accuracy:\", accuracy_score(ytest, xgb_ypred))\n","print(\"\\nClassification Report:\\n\", classification_report(ytest, xgb_ypred))\n","\n","# Assuming y_true and y_pred are your true labels and predicted labels\n","conf_matrix = confusion_matrix(ytest, xgb_ypred)\n","\n","# Calculate evaluation metrics\n","accuracy = accuracy_score(ytest, xgb_ypred)\n","precision = precision_score(ytest, xgb_ypred)\n","recall = recall_score(ytest, xgb_ypred)\n","f1 = f1_score(ytest, xgb_ypred)\n","\n","# Display the confusion matrix and metrics\n","print(\"Confusion Matrix:\")\n","print(conf_matrix)\n","print(\"Accuracy:\", accuracy)\n","print(\"Precision:\", precision)\n","print(\"Recall:\", recall)\n","print(\"F1 Score:\", f1)"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Jason\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Users\\Jason\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n","  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n","c:\\Users\\Jason\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n","  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Accuracy</th>\n","      <th>F1_score</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>LogisticRegression() _ Train Details</th>\n","      <td>95</td>\n","      <td>6</td>\n","      <td>96</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>LogisticRegression() _ Test Details</th>\n","      <td>96</td>\n","      <td>7</td>\n","      <td>67</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>KNeighborsClassifier() _ Train Details</th>\n","      <td>96</td>\n","      <td>54</td>\n","      <td>74</td>\n","      <td>43</td>\n","    </tr>\n","    <tr>\n","      <th>KNeighborsClassifier() _ Test Details</th>\n","      <td>96</td>\n","      <td>47</td>\n","      <td>62</td>\n","      <td>37</td>\n","    </tr>\n","    <tr>\n","      <th>DecisionTreeClassifier() _ Train Details</th>\n","      <td>100</td>\n","      <td>99</td>\n","      <td>99</td>\n","      <td>98</td>\n","    </tr>\n","    <tr>\n","      <th>DecisionTreeClassifier() _ Test Details</th>\n","      <td>97</td>\n","      <td>69</td>\n","      <td>64</td>\n","      <td>73</td>\n","    </tr>\n","    <tr>\n","      <th>ExtraTreeClassifier() _ Train Details</th>\n","      <td>100</td>\n","      <td>99</td>\n","      <td>99</td>\n","      <td>98</td>\n","    </tr>\n","    <tr>\n","      <th>ExtraTreeClassifier() _ Test Details</th>\n","      <td>96</td>\n","      <td>58</td>\n","      <td>55</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>RandomForestClassifier() _ Train Details</th>\n","      <td>100</td>\n","      <td>99</td>\n","      <td>99</td>\n","      <td>98</td>\n","    </tr>\n","    <tr>\n","      <th>RandomForestClassifier() _ Test Details</th>\n","      <td>98</td>\n","      <td>76</td>\n","      <td>94</td>\n","      <td>63</td>\n","    </tr>\n","    <tr>\n","      <th>ExtraTreesClassifier() _ Train Details</th>\n","      <td>100</td>\n","      <td>99</td>\n","      <td>99</td>\n","      <td>98</td>\n","    </tr>\n","    <tr>\n","      <th>ExtraTreesClassifier() _ Test Details</th>\n","      <td>98</td>\n","      <td>74</td>\n","      <td>91</td>\n","      <td>63</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                         Accuracy F1_score Precision Recall\n","LogisticRegression() _ Train Details           95        6        96      3\n","LogisticRegression() _ Test Details            96        7        67      4\n","KNeighborsClassifier() _ Train Details         96       54        74     43\n","KNeighborsClassifier() _ Test Details          96       47        62     37\n","DecisionTreeClassifier() _ Train Details      100       99        99     98\n","DecisionTreeClassifier() _ Test Details        97       69        64     73\n","ExtraTreeClassifier() _ Train Details         100       99        99     98\n","ExtraTreeClassifier() _ Test Details           96       58        55     60\n","RandomForestClassifier() _ Train Details      100       99        99     98\n","RandomForestClassifier() _ Test Details        98       76        94     63\n","ExtraTreesClassifier() _ Train Details        100       99        99     98\n","ExtraTreesClassifier() _ Test Details          98       74        91     63"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["# import the models \n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.tree import ExtraTreeClassifier\n","from sklearn.ensemble import ExtraTreesClassifier\n","\n","# perform model training and model comparisons\n","list_of_models = [LogisticRegression() , KNeighborsClassifier() , \n","                  DecisionTreeClassifier() ,ExtraTreeClassifier(), RandomForestClassifier(), ExtraTreesClassifier()]\n","classification_report = pd.DataFrame(columns=['Accuracy','F1_score','Precision','Recall'])\n","\n","for model in list_of_models :\n","    model = model.fit(xtrain, ytrain)\n","    for i in range(2) :\n","        if i == 0 :\n","            to_pred = xtrain\n","            pred = ytrain\n","            title = 'Train'\n","            \n","        else :\n","            to_pred = xtest\n","            pred = ytest\n","            title = 'Test'\n","        y_pred = model.predict(to_pred)\n","        acc = round(accuracy_score(pred , y_pred)*100)\n","        f1 = round(f1_score(pred , y_pred)*100)\n","        prec = round(precision_score(pred , y_pred)*100)\n","        recall = round(recall_score(pred , y_pred)*100)\n","        d = pd.DataFrame(data=np.array([acc,f1,prec,recall]).reshape(1,4) \n","                     , columns=['Accuracy' , 'F1_score' , 'Precision' , 'Recall'])  \n","        classification_report = pd.concat([classification_report , d])\n","        classification_report.rename( index= { 0 :'{} _ {} Details'.format(model , title) } ,inplace=True )\n","pd.options.display.max_rows = 15\n","classification_report"]},{"cell_type":"markdown","metadata":{"id":"wEf5AhiexCfL"},"source":["## Use SMOTE for oversampling"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":47,"status":"ok","timestamp":1700654574235,"user":{"displayName":"lo zh","userId":"05866467891459786403"},"user_tz":-480},"id":"qphAAFhs2i1G","outputId":"e2f8310b-8d92-4b31-b2b0-1e235a028b2b"},"outputs":[{"data":{"text/plain":["fraudulent\n","0    17014\n","1      866\n","Name: count, dtype: int64"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["target_var.value_counts()"]},{"cell_type":"code","execution_count":49,"metadata":{"executionInfo":{"elapsed":38,"status":"ok","timestamp":1700654574235,"user":{"displayName":"lo zh","userId":"05866467891459786403"},"user_tz":-480},"id":"Mfn_aiAt2mZW"},"outputs":[],"source":["# looking at the target distribution, lets resample to make it around 60:40 ratio\n","majority_class_samples = 13591\n","minority_class_samples = (majority_class_samples / 0.6) * 0.4\n","resampling_strategy = {0: majority_class_samples, 1: minority_class_samples}"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[],"source":["# !pip install imblearn # install package if the package is not available"]},{"cell_type":"code","execution_count":51,"metadata":{"executionInfo":{"elapsed":9446,"status":"ok","timestamp":1700654583644,"user":{"displayName":"lo zh","userId":"05866467891459786403"},"user_tz":-480},"id":"5ZgpS6K30hpM"},"outputs":[],"source":["from imblearn.over_sampling import SMOTENC # smotenc is used as it can handle categorical variable\n","from imblearn.over_sampling import SMOTE\n","\n","# oversampling\n","smote_nc = SMOTENC(categorical_features=[x for x in range(8)], random_state=0) # [x for x in range(544)]\n","xtrain_resampled, ytrain_resampled = smote_nc.fit_resample(xtrain, ytrain)\n","\n","# smote = SMOTE(random_state=0)\n","# xtrain_resampled, ytrain_resampled = smote.fit_resample(xtrain, ytrain)"]},{"cell_type":"code","execution_count":52,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46830,"status":"ok","timestamp":1700654630438,"user":{"displayName":"lo zh","userId":"05866467891459786403"},"user_tz":-480},"id":"55G0Aane7d-_","outputId":"df77ecad-434f-4c15-93a2-7b23959615a5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Random Forest:\n","Accuracy: 0.9779082774049217\n","\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.99      0.99      0.99      3423\n","           1       0.75      0.73      0.74       153\n","\n","    accuracy                           0.98      3576\n","   macro avg       0.87      0.86      0.86      3576\n","weighted avg       0.98      0.98      0.98      3576\n","\n","Confusion Matrix:\n","[[3386   37]\n"," [  42  111]]\n","Accuracy: 0.9779082774049217\n","Precision: 0.75\n","Recall: 0.7254901960784313\n","F1 Score: 0.7375415282392026\n"]}],"source":["# model training - Random Forest\n","from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, classification_report\n","\n","# train model\n","rfc = RandomForestClassifier(random_state=0)\n","rfc.fit(xtrain_resampled, ytrain_resampled)\n","\n","# predictions\n","rfc_ypred = rfc.predict(xtest)\n","\n","# Evaluate the Random Forest model\n","print(\"Random Forest:\")\n","print(\"Accuracy:\", accuracy_score(ytest, rfc_ypred))\n","print(\"\\nClassification Report:\\n\", classification_report(ytest, rfc_ypred))\n","\n","# Assuming y_true and y_pred are your true labels and predicted labels\n","conf_matrix = confusion_matrix(ytest, rfc_ypred)\n","\n","# Calculate evaluation metrics\n","accuracy = accuracy_score(ytest, rfc_ypred)\n","precision = precision_score(ytest, rfc_ypred)\n","recall = recall_score(ytest, rfc_ypred)\n","f1 = f1_score(ytest, rfc_ypred)\n","\n","# Display the confusion matrix and metrics\n","print(\"Confusion Matrix:\")\n","print(conf_matrix)\n","print(\"Accuracy:\", accuracy)\n","print(\"Precision:\", precision)\n","print(\"Recall:\", recall)\n","print(\"F1 Score:\", f1)"]},{"cell_type":"code","execution_count":53,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23635,"status":"ok","timestamp":1700654654039,"user":{"displayName":"lo zh","userId":"05866467891459786403"},"user_tz":-480},"id":"VUxakkCA7hr-","outputId":"6263cfa2-a8d3-43fc-d1d6-36270eafe83b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Logistic Regression:\n","Accuracy: 0.6434563758389261\n","\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.99      0.64      0.77      3423\n","           1       0.09      0.82      0.17       153\n","\n","    accuracy                           0.64      3576\n","   macro avg       0.54      0.73      0.47      3576\n","weighted avg       0.95      0.64      0.75      3576\n","\n","Confusion Matrix:\n","[[2175 1248]\n"," [  27  126]]\n","Accuracy: 0.6434563758389261\n","Precision: 0.09170305676855896\n","Recall: 0.8235294117647058\n","F1 Score: 0.1650294695481336\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\Jason\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]}],"source":["# model training - Random Forest\n","from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, classification_report\n","\n","# train model\n","lr = LogisticRegression(random_state=0)\n","lr.fit(xtrain_resampled, ytrain_resampled)\n","\n","# predictions\n","lr_ypred = lr.predict(xtest)\n","\n","# Evaluate the Random Forest model\n","print(\"Logistic Regression:\")\n","print(\"Accuracy:\", accuracy_score(ytest, lr_ypred))\n","print(\"\\nClassification Report:\\n\", classification_report(ytest, lr_ypred))\n","\n","# Assuming y_true and y_pred are your true labels and predicted labels\n","conf_matrix = confusion_matrix(ytest, lr_ypred)\n","\n","# Calculate evaluation metrics\n","accuracy = accuracy_score(ytest, lr_ypred)\n","precision = precision_score(ytest, lr_ypred)\n","recall = recall_score(ytest, lr_ypred)\n","f1 = f1_score(ytest, lr_ypred)\n","\n","# Display the confusion matrix and metrics\n","print(\"Confusion Matrix:\")\n","print(conf_matrix)\n","print(\"Accuracy:\", accuracy)\n","print(\"Precision:\", precision)\n","print(\"Recall:\", recall)\n","print(\"F1 Score:\", f1)"]},{"cell_type":"code","execution_count":54,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":107314,"status":"ok","timestamp":1700654761347,"user":{"displayName":"lo zh","userId":"05866467891459786403"},"user_tz":-480},"id":"RvMkkoOxQxyY","outputId":"7e679e84-1178-4b05-d439-6e3855a37f6e"},"outputs":[{"name":"stdout","output_type":"stream","text":["XGBoost:\n","Accuracy: 0.9801454138702461\n","\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.99      0.99      0.99      3423\n","           1       0.76      0.79      0.77       153\n","\n","    accuracy                           0.98      3576\n","   macro avg       0.87      0.89      0.88      3576\n","weighted avg       0.98      0.98      0.98      3576\n","\n","Confusion Matrix:\n","[[3384   39]\n"," [  32  121]]\n","Accuracy: 0.9801454138702461\n","Precision: 0.75625\n","Recall: 0.7908496732026143\n","F1 Score: 0.7731629392971247\n"]}],"source":["# model training - xgboost\n","from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, classification_report\n","\n","# Create an instance of XGBClassifier\n","xgb_classifier = XGBClassifier(random_state=0)\n","xtrain.columns = xtrain.columns.astype(str) # keep column name\n","xgb_classifier.fit(xtrain_resampled, ytrain_resampled)\n","\n","# Make predictions on the test set\n","xtest.columns = xtest.columns.astype(str) # keep column name\n","xgb_ypred = xgb_classifier.predict(xtest)\n","\n","# Evaluate the xgboost model\n","print(\"XGBoost:\")\n","print(\"Accuracy:\", accuracy_score(ytest, xgb_ypred))\n","print(\"\\nClassification Report:\\n\", classification_report(ytest, xgb_ypred))\n","\n","# Assuming y_true and y_pred are your true labels and predicted labels\n","conf_matrix = confusion_matrix(ytest, xgb_ypred)\n","\n","# Calculate evaluation metrics\n","accuracy = accuracy_score(ytest, xgb_ypred)\n","precision = precision_score(ytest, xgb_ypred)\n","recall = recall_score(ytest, xgb_ypred)\n","f1 = f1_score(ytest, xgb_ypred)\n","\n","# Display the confusion matrix and metrics\n","print(\"Confusion Matrix:\")\n","print(conf_matrix)\n","print(\"Accuracy:\", accuracy)\n","print(\"Precision:\", precision)\n","print(\"Recall:\", recall)\n","print(\"F1 Score:\", f1)"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Jason\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","c:\\Users\\Jason\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n","  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n","c:\\Users\\Jason\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n","  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Accuracy</th>\n","      <th>F1_score</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>LogisticRegression() _ Train Details</th>\n","      <td>71</td>\n","      <td>73</td>\n","      <td>68</td>\n","      <td>78</td>\n","    </tr>\n","    <tr>\n","      <th>LogisticRegression() _ Test Details</th>\n","      <td>64</td>\n","      <td>17</td>\n","      <td>9</td>\n","      <td>82</td>\n","    </tr>\n","    <tr>\n","      <th>KNeighborsClassifier() _ Train Details</th>\n","      <td>94</td>\n","      <td>94</td>\n","      <td>91</td>\n","      <td>98</td>\n","    </tr>\n","    <tr>\n","      <th>KNeighborsClassifier() _ Test Details</th>\n","      <td>87</td>\n","      <td>32</td>\n","      <td>21</td>\n","      <td>72</td>\n","    </tr>\n","    <tr>\n","      <th>DecisionTreeClassifier() _ Train Details</th>\n","      <td>100</td>\n","      <td>100</td>\n","      <td>100</td>\n","      <td>100</td>\n","    </tr>\n","    <tr>\n","      <th>DecisionTreeClassifier() _ Test Details</th>\n","      <td>96</td>\n","      <td>61</td>\n","      <td>51</td>\n","      <td>75</td>\n","    </tr>\n","    <tr>\n","      <th>ExtraTreeClassifier() _ Train Details</th>\n","      <td>100</td>\n","      <td>100</td>\n","      <td>100</td>\n","      <td>100</td>\n","    </tr>\n","    <tr>\n","      <th>ExtraTreeClassifier() _ Test Details</th>\n","      <td>95</td>\n","      <td>57</td>\n","      <td>45</td>\n","      <td>76</td>\n","    </tr>\n","    <tr>\n","      <th>RandomForestClassifier() _ Train Details</th>\n","      <td>100</td>\n","      <td>100</td>\n","      <td>100</td>\n","      <td>100</td>\n","    </tr>\n","    <tr>\n","      <th>RandomForestClassifier() _ Test Details</th>\n","      <td>98</td>\n","      <td>74</td>\n","      <td>74</td>\n","      <td>73</td>\n","    </tr>\n","    <tr>\n","      <th>ExtraTreesClassifier() _ Train Details</th>\n","      <td>100</td>\n","      <td>100</td>\n","      <td>100</td>\n","      <td>100</td>\n","    </tr>\n","    <tr>\n","      <th>ExtraTreesClassifier() _ Test Details</th>\n","      <td>97</td>\n","      <td>71</td>\n","      <td>70</td>\n","      <td>73</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                         Accuracy F1_score Precision Recall\n","LogisticRegression() _ Train Details           71       73        68     78\n","LogisticRegression() _ Test Details            64       17         9     82\n","KNeighborsClassifier() _ Train Details         94       94        91     98\n","KNeighborsClassifier() _ Test Details          87       32        21     72\n","DecisionTreeClassifier() _ Train Details      100      100       100    100\n","DecisionTreeClassifier() _ Test Details        96       61        51     75\n","ExtraTreeClassifier() _ Train Details         100      100       100    100\n","ExtraTreeClassifier() _ Test Details           95       57        45     76\n","RandomForestClassifier() _ Train Details      100      100       100    100\n","RandomForestClassifier() _ Test Details        98       74        74     73\n","ExtraTreesClassifier() _ Train Details        100      100       100    100\n","ExtraTreesClassifier() _ Test Details          97       71        70     73"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["# perform model training and model comparisons\n","list_of_models = [LogisticRegression() , KNeighborsClassifier() , \n","                  DecisionTreeClassifier() ,ExtraTreeClassifier(), RandomForestClassifier(), ExtraTreesClassifier()]\n","classification_report = pd.DataFrame(columns=['Accuracy','F1_score','Precision','Recall'])\n","\n","for model in list_of_models :\n","    model = model.fit(xtrain_resampled, ytrain_resampled)\n","    for i in range(2) :\n","        if i == 0 :\n","            to_pred = xtrain_resampled\n","            pred = ytrain_resampled\n","            title = 'Train'\n","            \n","        else :\n","            to_pred = xtest\n","            pred = ytest\n","            title = 'Test'\n","        y_pred = model.predict(to_pred)\n","        acc = round(accuracy_score(pred , y_pred)*100)\n","        f1 = round(f1_score(pred , y_pred)*100)\n","        prec = round(precision_score(pred , y_pred)*100)\n","        recall = round(recall_score(pred , y_pred)*100)\n","        d = pd.DataFrame(data=np.array([acc,f1,prec,recall]).reshape(1,4) \n","                     , columns=['Accuracy' , 'F1_score' , 'Precision' , 'Recall'])  \n","        classification_report = pd.concat([classification_report , d])\n","        classification_report.rename( index= { 0 :'{} _ {} Details'.format(model , title) } ,inplace=True )\n","pd.options.display.max_rows = 15\n","classification_report"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}
